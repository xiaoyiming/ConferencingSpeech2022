# ConferencingSpeech2022 Datasets
This folder gives the conferencingSpeech2022 datasets download link and a brief introduction. Participants can divide the training set and development verification set according to their own needs. More detail can be found in.

# Datasets Brief Introduction
## Tencent Corpus
This dataset  includes reverberation and reverberation free situations. In the reverberation free situation, there are about 10k Chinese corpus and  all speech clips experience the simulated damage which will often be suffered in online conference. While, in the reverberation situation, simulated damage and live recorded speech clips are considered and totally count about 4k. The above dataset can be found in [website](https://share.weiyun.com/6Mn4bvOC).

##  NISQA Corpus
The NISQA Corpus includes more than 14,000 speech samples with simulated (e.g. codecs, packet-loss, background noise) and live (e.g. mobile phone, Zoom, Skype, WhatsApp) conditions. The corpus is already publicly available so it can only be used as part of the training and development test sets in the competition.
Subjective ratings are collected through an extension of P.808 Toolkit in which participants rated the overall quality and the quality dimensions Noisiness, Coloration, Discontinuity, and Loudness. Each clip has on average 5 valid votes.

## IU Bloomington Corpus
There are 36,000 speech signals (16-bit single-channel audios sampled at 16 kHz) extracted from COSINE  and VOiCESdatasets, each truncated between 3 to 6 seconds long, with a total length of around 45 hours.
About 10,000 corpus are offered in this competition.

## PSTN Corpus
The PSTN  Corpus contain 79,980 degraded speech clips with a duration
of 10 seconds were collected, 49,984 files based on noisy reference files, and 29,996 files based on clean reference files. The
files were then split into a training and validation set. 
